#!/usr/bin/env python
"""
vlg.py - Video List Getter
ç”¨é€”ï¼šä½¿ç”¨ yt-dlp è·å–ä½œè€…/é¢‘é“çš„è§†é¢‘åˆ—è¡¨ï¼Œè¾“å‡ºåˆ° CSV æ–‡ä»¶
æ”¯æŒå¹³å°ï¼šYouTubeã€Bilibili
"""
import argparse
import csv
import os
import re
import sys
import logging
import requests
import shutil
import tempfile
from datetime import datetime, timedelta
from dataclasses import dataclass
from typing import Optional, List

# Configure logging
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


@dataclass
class VideoEntry:
    """è§†é¢‘æ¡ç›®æ•°æ®ç±»"""

    upload_date: str
    title: str
    author: str
    url: str


class VideoListGetter:
    """è§†é¢‘åˆ—è¡¨è·å–å™¨ - ä½¿ç”¨ yt-dlp è·å–é¢‘é“/ä½œè€…çš„è§†é¢‘åˆ—è¡¨"""

    def __init__(self, cookies_file: Optional[str] = None):
        """
        åˆå§‹åŒ–è§†é¢‘åˆ—è¡¨è·å–å™¨

        Args:
            cookies_file: cookies æ–‡ä»¶è·¯å¾„ (Netscape æ ¼å¼)
        """
        original_cookies = cookies_file or self._find_cookies_file()
        self.cookies_file = None
        self._temp_cookie_file = None

        if original_cookies and os.path.exists(original_cookies):
            try:
                # åˆ›å»ºä¸´æ—¶å‰¯æœ¬ä»¥é¿å…ä¿®æ”¹åŸå§‹ cookies.txt
                fd, temp_path = tempfile.mkstemp(prefix="vlg_cookies_", suffix=".txt")
                os.close(fd)
                shutil.copy2(original_cookies, temp_path)
                self.cookies_file = temp_path
                self._temp_cookie_file = temp_path
                logger.debug(f"å·²åˆ›å»ºä¸´æ—¶ cookies æ–‡ä»¶: {temp_path}")
            except Exception as e:
                logger.warning(f"åˆ›å»ºä¸´æ—¶ cookies æ–‡ä»¶å¤±è´¥: {e}")
                self.cookies_file = original_cookies

    def cleanup(self):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        if self._temp_cookie_file and os.path.exists(self._temp_cookie_file):
            try:
                os.remove(self._temp_cookie_file)
                logger.debug(f"å·²æ¸…ç†ä¸´æ—¶ cookies æ–‡ä»¶: {self._temp_cookie_file}")
                self._temp_cookie_file = None
            except Exception as e:
                logger.warning(f"æ¸…ç†ä¸´æ—¶ cookies æ–‡ä»¶å¤±è´¥: {e}")

    def __del__(self):
        self.cleanup()

    def _find_cookies_file(self) -> Optional[str]:
        """æŸ¥æ‰¾é»˜è®¤çš„ cookies.txt æ–‡ä»¶"""
        default_path = os.path.join(
            os.path.dirname(os.path.abspath(__file__)), "cookies.txt"
        )
        if os.path.exists(default_path):
            return default_path
        return None

    def _get_ydl_opts(self, extract_flat: bool = True) -> dict:
        """
        è·å– yt-dlp é…ç½®é€‰é¡¹

        Args:
            extract_flat: æ˜¯å¦åªæå–å…ƒæ•°æ®ä¸ä¸‹è½½
        """
        opts = {
            "quiet": True,
            "no_warnings": True,
            "extract_flat": extract_flat,
            "ignoreerrors": True,
        }

        if self.cookies_file and os.path.exists(self.cookies_file):
            opts["cookiefile"] = self.cookies_file
            logger.info(f"ä½¿ç”¨ cookies æ–‡ä»¶: {self.cookies_file}")

        return opts

    def detect_platform(self, url: str) -> str:
        """
        æ£€æµ‹ URL å¯¹åº”çš„å¹³å°

        Args:
            url: é¢‘é“/ä½œè€… URL

        Returns:
            å¹³å°åç§°: 'youtube', 'bilibili' æˆ– 'unknown'
        """
        url_lower = url.lower()

        if "youtube.com" in url_lower or "youtu.be" in url_lower:
            return "youtube"
        elif "bilibili.com" in url_lower or "b23.tv" in url_lower:
            return "bilibili"
        else:
            return "unknown"

    def normalize_channel_url(self, url: str) -> str:
        """
        è§„èŒƒåŒ–é¢‘é“ URLï¼Œç¡®ä¿è·å–è§†é¢‘åˆ—è¡¨

        Args:
            url: è¾“å…¥çš„é¢‘é“ URL

        Returns:
            è§„èŒƒåŒ–åçš„ URL
        """
        platform = self.detect_platform(url)

        if platform == "youtube":
            # å¤„ç† YouTube é¢‘é“ URL
            # æ”¯æŒæ ¼å¼: /channel/xxx, /@username, /c/xxx, /user/xxx
            if "/videos" not in url:
                # ç§»é™¤æœ«å°¾æ–œæ 
                url = url.rstrip("/")
                # æ·»åŠ  /videos åç¼€ä»¥è·å–è§†é¢‘åˆ—è¡¨
                url = url + "/videos"
            return url

        elif platform == "bilibili":
            # å¤„ç† Bilibili ç”¨æˆ· URL
            # æ ¼å¼: space.bilibili.com/uid æˆ– bilibili.com/space/uid
            # æå–ç”¨æˆ· ID
            match = re.search(r"space\.bilibili\.com/(\d+)", url)
            if match:
                uid = match.group(1)
                # è¿”å›ç”¨æˆ·æŠ•ç¨¿è§†é¢‘é¡µé¢
                return f"https://space.bilibili.com/{uid}/video"

            match = re.search(r"bilibili\.com/space/(\d+)", url)
            if match:
                uid = match.group(1)
                return f"https://space.bilibili.com/{uid}/video"

            return url

        return url

    def parse_date_range(
        self,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        days: Optional[int] = None,
    ) -> tuple[Optional[datetime], Optional[datetime]]:
        """
        è§£ææ—¥æœŸèŒƒå›´

        Args:
            start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD æ ¼å¼)
            end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD æ ¼å¼)
            days: æœ€è¿‘ N å¤©

        Returns:
            (å¼€å§‹æ—¥æœŸ, ç»“æŸæ—¥æœŸ) å…ƒç»„
        """
        end_dt = None
        start_dt = None

        if days:
            end_dt = datetime.now()
            start_dt = end_dt - timedelta(days=days)
        else:
            if end_date:
                try:
                    end_dt = datetime.strptime(end_date, "%Y-%m-%d")
                    # è®¾ç½®ä¸ºå½“å¤©ç»“æŸ
                    end_dt = end_dt.replace(hour=23, minute=59, second=59)
                except ValueError:
                    logger.warning(f"æ— æ•ˆçš„ç»“æŸæ—¥æœŸæ ¼å¼: {end_date}")

            if start_date:
                try:
                    start_dt = datetime.strptime(start_date, "%Y-%m-%d")
                except ValueError:
                    logger.warning(f"æ— æ•ˆçš„å¼€å§‹æ—¥æœŸæ ¼å¼: {start_date}")

        return start_dt, end_dt

    def _parse_upload_date(self, date_str: Optional[str]) -> Optional[datetime]:
        """
        è§£æ yt-dlp è¿”å›çš„ä¸Šä¼ æ—¥æœŸ

        Args:
            date_str: æ—¥æœŸå­—ç¬¦ä¸² (YYYYMMDD æ ¼å¼)

        Returns:
            datetime å¯¹è±¡æˆ– None
        """
        if not date_str:
            return None

        try:
            # yt-dlp é€šå¸¸è¿”å› YYYYMMDD æ ¼å¼
            return datetime.strptime(str(date_str), "%Y%m%d")
        except ValueError:
            try:
                # å°è¯•å…¶ä»–å¸¸è§æ ¼å¼
                return datetime.strptime(str(date_str), "%Y-%m-%d")
            except ValueError:
                return None

    def _format_date(self, date_str: Optional[str]) -> str:
        """
        æ ¼å¼åŒ–æ—¥æœŸä¸ºå¯è¯»æ ¼å¼

        Args:
            date_str: åŸå§‹æ—¥æœŸå­—ç¬¦ä¸²

        Returns:
            æ ¼å¼åŒ–åçš„æ—¥æœŸå­—ç¬¦ä¸²
        """
        if not date_str:
            return "æœªçŸ¥"

        dt = self._parse_upload_date(date_str)
        if dt:
            return dt.strftime("%Y-%m-%d")
        return str(date_str)

    def _get_bilibili_uid(self, url: str) -> Optional[str]:
        """
        ä» Bilibili URL ä¸­æå–ç”¨æˆ· ID

        Args:
            url: Bilibili ç”¨æˆ·ç©ºé—´ URL

        Returns:
            ç”¨æˆ· ID æˆ– None
        """
        match = re.search(r"space\.bilibili\.com/(\d+)", url)
        if match:
            return match.group(1)

        match = re.search(r"bilibili\.com/space/(\d+)", url)
        if match:
            return match.group(1)

        return None

    def _get_bilibili_videos_via_ytdlp(
        self,
        url: str,
        max_videos: Optional[int] = None,
        start_dt: Optional[datetime] = None,
        end_dt: Optional[datetime] = None,
    ) -> List[VideoEntry]:
        """
        ä½¿ç”¨ yt-dlp è·å– Bilibili ç”¨æˆ·æŠ•ç¨¿è§†é¢‘åˆ—è¡¨

        Args:
            url: ç”¨æˆ·ç©ºé—´è§†é¢‘ URL
            max_videos: æœ€å¤§è§†é¢‘æ•°é‡
            start_dt: å¼€å§‹æ—¥æœŸè¿‡æ»¤
            end_dt: ç»“æŸæ—¥æœŸè¿‡æ»¤

        Returns:
            VideoEntry åˆ—è¡¨
        """
        import yt_dlp

        videos: List[VideoEntry] = []

        # ç¬¬ä¸€æ­¥ï¼šä½¿ç”¨ flat æ¨¡å¼è·å–è§†é¢‘ ID åˆ—è¡¨
        ydl_opts_flat = self._get_ydl_opts(extract_flat=True)
        if max_videos:
            ydl_opts_flat["playlistend"] = max_videos * 2

        video_ids = []
        channel_name = "æœªçŸ¥"

        with yt_dlp.YoutubeDL(ydl_opts_flat) as ydl:
            try:
                result = ydl.extract_info(url, download=False)
                if result:
                    channel_name = (
                        result.get("uploader")
                        or result.get("channel")
                        or result.get("title")
                        or "æœªçŸ¥"
                    )
                    entries = result.get("entries", [])
                    for entry in entries:
                        if entry and entry.get("id"):
                            video_ids.append(entry.get("id"))
            except Exception as e:
                logger.error(f"è·å–è§†é¢‘åˆ—è¡¨å¤±è´¥: {e}")
                return videos

        if not video_ids:
            logger.warning("æœªæ‰¾åˆ°è§†é¢‘")
            return videos

        print(f"ğŸ“Š æ‰¾åˆ° {len(video_ids)} ä¸ªè§†é¢‘ï¼Œæ­£åœ¨è·å–è¯¦ç»†ä¿¡æ¯...")

        # ç¬¬äºŒæ­¥ï¼šé€ä¸ªè·å–è§†é¢‘è¯¦ç»†ä¿¡æ¯ï¼ˆé flat æ¨¡å¼ï¼‰
        ydl_opts_detail = self._get_ydl_opts(extract_flat=False)

        # é™åˆ¶éœ€è¦è·å–çš„è§†é¢‘æ•°é‡
        target_count = max_videos if max_videos else len(video_ids)
        processed = 0

        with yt_dlp.YoutubeDL(ydl_opts_detail) as ydl:
            for video_id in video_ids:
                if len(videos) >= target_count:
                    break

                video_url = f"https://www.bilibili.com/video/{video_id}"

                try:
                    logger.debug(f"æ­£åœ¨è·å–è§†é¢‘ {video_id} çš„è¯¦ç»†ä¿¡æ¯...")
                    info = ydl.extract_info(video_url, download=False)
                    if not info:
                        logger.debug(f"è§†é¢‘ {video_id} ä¿¡æ¯ä¸ºç©ºï¼Œè·³è¿‡")
                        continue

                    # è·å–ä¸Šä¼ æ—¥æœŸ
                    upload_date_str = info.get("upload_date")
                    upload_dt = self._parse_upload_date(upload_date_str)

                    # æ—¥æœŸè¿‡æ»¤
                    if upload_dt:
                        if start_dt and upload_dt < start_dt:
                            # è§†é¢‘å¯èƒ½æŒ‰æ—¶é—´æ’åºï¼Œæ—©äºå¼€å§‹æ—¥æœŸå¯ä»¥ç»§ç»­å°è¯•
                            processed += 1
                            # å¦‚æœå·²ç»å¤„ç†äº†å¾ˆå¤šä½†æ²¡æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„ï¼Œå¯èƒ½éœ€è¦ç»§ç»­
                            if processed > target_count * 2:
                                break
                            continue
                        if end_dt and upload_dt > end_dt:
                            continue

                    # è·å–ä½œè€…åç§°
                    author = info.get("uploader") or info.get("channel") or channel_name
                    logger.debug(
                        f"è§†é¢‘ {video_id} ä½œè€…: {author}, æ ‡é¢˜: {info.get('title', 'æœªçŸ¥æ ‡é¢˜')}"
                    )

                    video = VideoEntry(
                        upload_date=self._format_date(upload_date_str),
                        title=info.get("title", "æœªçŸ¥æ ‡é¢˜"),
                        author=author,
                        url=video_url,
                    )

                    videos.append(video)
                    processed += 1

                except Exception as e:
                    logger.debug(f"è·å–è§†é¢‘ {video_id} ä¿¡æ¯å¤±è´¥: {e}")
                    continue

        # æŒ‰æ—¥æœŸæ’åº
        videos.sort(key=lambda x: x.upload_date, reverse=True)
        print(f"âœ… ç­›é€‰åå…± {len(videos)} ä¸ªè§†é¢‘")

        return videos

    def _get_bilibili_videos_via_api(
        self,
        uid: str,
        max_videos: Optional[int] = None,
        start_dt: Optional[datetime] = None,
        end_dt: Optional[datetime] = None,
    ) -> List[VideoEntry]:
        """
        ä½¿ç”¨ç¬¬ä¸‰æ–¹ uapis.cn API è·å–ç”¨æˆ·æŠ•ç¨¿è§†é¢‘åˆ—è¡¨

        API æ–‡æ¡£: https://uapis.cn/docs/api-reference/get-social-bilibili-archives

        Args:
            uid: ç”¨æˆ· ID (mid)
            max_videos: æœ€å¤§è§†é¢‘æ•°é‡
            start_dt: å¼€å§‹æ—¥æœŸè¿‡æ»¤
            end_dt: ç»“æŸæ—¥æœŸè¿‡æ»¤

        Returns:
            VideoEntry åˆ—è¡¨
        """
        import time

        videos: List[VideoEntry] = []
        page = 1
        page_size = 20  # uapis.cn é»˜è®¤æ¯é¡µ 20 æ¡

        # uapis.cn API ç«¯ç‚¹
        api_url = "https://uapis.cn/api/v1/social/bilibili/archives"

        while True:
            params = {
                "mid": uid,
                "ps": page_size,
                "pn": page,
                "orderby": "pubdate",  # æŒ‰æœ€æ–°å‘å¸ƒæ’åº
            }

            try:
                response = requests.get(api_url, params=params, timeout=15)
                response.raise_for_status()
                data = response.json()

                # æ£€æŸ¥é”™è¯¯å“åº” (400/404/500 ç­‰)
                if "code" in data:
                    error_code = data.get("code", "")
                    error_msg = data.get("message", "æœªçŸ¥é”™è¯¯")
                    logger.warning(f"uapis.cn API è¿”å›é”™è¯¯: [{error_code}] {error_msg}")
                    break

                # è§£æå“åº”æ•°æ®
                video_list = data.get("videos", [])
                total = data.get("total", 0)

                if not video_list:
                    break

                for video_info in video_list:
                    # è§£æå‘å¸ƒæ—¶é—´ï¼ˆæ—¶é—´æˆ³ï¼‰
                    publish_ts = video_info.get("publish_time", 0)
                    if publish_ts:
                        upload_dt = datetime.fromtimestamp(publish_ts)
                        upload_date_str = upload_dt.strftime("%Y-%m-%d")
                    else:
                        upload_dt = None
                        upload_date_str = "æœªçŸ¥"

                    # æ—¥æœŸè¿‡æ»¤
                    if upload_dt:
                        if start_dt and upload_dt < start_dt:
                            # ç”±äºæŒ‰å‘å¸ƒæ—¶é—´é™åºæ’åˆ—ï¼Œå¦‚æœå½“å‰è§†é¢‘æ—©äºå¼€å§‹æ—¥æœŸï¼Œåé¢çš„æ›´æ—©ï¼Œå¯ä»¥ç›´æ¥ç»“æŸ
                            return videos
                        if end_dt and upload_dt > end_dt:
                            continue

                    bvid = video_info.get("bvid", "")
                    video_url = f"https://www.bilibili.com/video/{bvid}" if bvid else ""

                    # æ³¨æ„: uapis.cn API å“åº”ä¸­æ²¡æœ‰ author å­—æ®µï¼Œéœ€è¦ä»å…¶ä»–åœ°æ–¹è·å–æˆ–ç•™ç©º
                    video = VideoEntry(
                        upload_date=upload_date_str,
                        title=video_info.get("title", "æœªçŸ¥æ ‡é¢˜"),
                        author="",  # API å“åº”ä¸­æœªæä¾› authorï¼Œåç»­å¯é€šè¿‡å…¶ä»–æ–¹å¼è¡¥å……
                        url=video_url,
                    )

                    videos.append(video)

                    # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å¤§æ•°é‡
                    if max_videos and len(videos) >= max_videos:
                        return videos

                # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ›´å¤šé¡µ
                if page * page_size >= total:
                    break

                page += 1
                time.sleep(0.3)  # åˆ†é¡µè¯·æ±‚é—´æ·»åŠ çŸ­æš‚å»¶è¿Ÿ

            except requests.RequestException as e:
                logger.error(f"è¯·æ±‚ uapis.cn API å¤±è´¥: {e}")
                break
            except Exception as e:
                logger.error(f"è§£æ uapis.cn API å“åº”å¤±è´¥: {e}")
                break

        return videos

    def get_video_list(
        self,
        channel_url: str,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        days: Optional[int] = None,
        max_videos: Optional[int] = None,
    ) -> List[VideoEntry]:
        """
        è·å–é¢‘é“/ä½œè€…çš„è§†é¢‘åˆ—è¡¨

        Args:
            channel_url: é¢‘é“/ä½œè€… URL
            start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
            end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
            days: æœ€è¿‘ N å¤©
            max_videos: æœ€å¤§è§†é¢‘æ•°é‡

        Returns:
            VideoEntry åˆ—è¡¨
        """
        # è§„èŒƒåŒ– URL
        url = self.normalize_channel_url(channel_url)
        platform = self.detect_platform(url)

        print(f"ğŸ“º å¹³å°: {platform.upper()}")
        print(f"ğŸ”— URL: {url}")
        print("â³ æ­£åœ¨è·å–è§†é¢‘åˆ—è¡¨...")

        # è§£ææ—¥æœŸèŒƒå›´
        start_dt, end_dt = self.parse_date_range(start_date, end_date, days)

        if start_dt or end_dt:
            date_range_str = []
            if start_dt:
                date_range_str.append(f"ä» {start_dt.strftime('%Y-%m-%d')}")
            if end_dt:
                date_range_str.append(f"åˆ° {end_dt.strftime('%Y-%m-%d')}")
            print(f"ğŸ“… æ—¶é—´èŒƒå›´: {' '.join(date_range_str)}")

        videos: List[VideoEntry] = []

        # å¯¹äºæ‰€æœ‰å¹³å°ï¼Œä½¿ç”¨ yt-dlp
        try:
            import yt_dlp
        except ImportError:
            print("é”™è¯¯: yt-dlp æœªå®‰è£…")
            print("è¯·è¿è¡Œ: pip install yt-dlp")
            sys.exit(1)

        # æ ¹æ®å¹³å°é€‰æ‹©ä¸åŒçš„è·å–æ–¹å¼
        if platform == "bilibili":
            # å¯¹äº Bilibiliï¼Œé¦–å…ˆå°è¯•ä½¿ç”¨ API è·å–å®Œæ•´ä¿¡æ¯
            uid = self._get_bilibili_uid(channel_url)
            if uid:
                videos = self._get_bilibili_videos_via_api(
                    uid=uid,
                    max_videos=max_videos,
                    start_dt=start_dt,
                    end_dt=end_dt,
                )
                if videos:
                    print(f"âœ… ç­›é€‰åå…± {len(videos)} ä¸ªè§†é¢‘")
                    return videos
                # å¦‚æœ API å¤±è´¥ï¼Œé™çº§ä½¿ç”¨ yt-dlpï¼ˆé flat æ¨¡å¼ï¼‰
                logger.info("API è·å–å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ yt-dlp...")
                return self._get_bilibili_videos_via_ytdlp(
                    url=url,
                    max_videos=max_videos,
                    start_dt=start_dt,
                    end_dt=end_dt,
                )

        # è·å–è§†é¢‘åˆ—è¡¨
        ydl_opts = self._get_ydl_opts(extract_flat=True)

        # è®¾ç½®æœ€å¤§ä¸‹è½½æ•°é‡ï¼ˆå¦‚æœæŒ‡å®šï¼‰
        if max_videos:
            ydl_opts["playlistend"] = max_videos * 2  # ç•™äº›ä½™é‡ç”¨äºæ—¥æœŸè¿‡æ»¤

        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            try:
                result = ydl.extract_info(url, download=False)

                if not result:
                    logger.error("æ— æ³•è·å–é¢‘é“ä¿¡æ¯")
                    return videos

                # è·å–é¢‘é“åç§°
                channel_name = (
                    result.get("uploader")
                    or result.get("channel")
                    or result.get("title")
                    or "æœªçŸ¥"
                )

                # å¤„ç†æ’­æ”¾åˆ—è¡¨/é¢‘é“ä¸­çš„è§†é¢‘
                entries = result.get("entries", [])

                if not entries:
                    # å¦‚æœæ²¡æœ‰ entriesï¼Œå¯èƒ½æ˜¯å•ä¸ªè§†é¢‘
                    if result.get("id"):
                        entries = [result]

                print(f"ğŸ“Š æ‰¾åˆ° {len(entries) if entries else 0} ä¸ªè§†é¢‘")

                for entry in entries:
                    if not entry:
                        continue

                    # è·å–ä¸Šä¼ æ—¥æœŸ
                    upload_date_str = entry.get("upload_date")
                    upload_dt = self._parse_upload_date(upload_date_str)

                    # æ—¥æœŸè¿‡æ»¤
                    if upload_dt:
                        if start_dt and upload_dt < start_dt:
                            continue
                        if end_dt and upload_dt > end_dt:
                            continue

                    # æ„å»ºè§†é¢‘ URL
                    video_id = entry.get("id", "")
                    video_url = entry.get("url") or entry.get("webpage_url") or ""

                    if not video_url and video_id:
                        if platform == "youtube":
                            video_url = f"https://www.youtube.com/watch?v={video_id}"
                        elif platform == "bilibili":
                            video_url = f"https://www.bilibili.com/video/{video_id}"

                    # è·å–ä½œè€…åç§°
                    author = (
                        entry.get("uploader") or entry.get("channel") or channel_name
                    )

                    video = VideoEntry(
                        upload_date=self._format_date(upload_date_str),
                        title=entry.get("title", "æœªçŸ¥æ ‡é¢˜"),
                        author=author,
                        url=video_url,
                    )

                    videos.append(video)

                    # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å¤§æ•°é‡
                    if max_videos and len(videos) >= max_videos:
                        break

            except Exception as e:
                logger.error(f"è·å–è§†é¢‘åˆ—è¡¨å¤±è´¥: {e}")
                raise

        # æŒ‰æ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
        videos.sort(key=lambda x: x.upload_date, reverse=True)

        print(f"âœ… ç­›é€‰åå…± {len(videos)} ä¸ªè§†é¢‘")

        return videos

    def export_to_csv(
        self, videos: List[VideoEntry], output_path: str, encoding: str = "utf-8-sig"
    ) -> str:
        """
        å°†è§†é¢‘åˆ—è¡¨å¯¼å‡ºåˆ° CSV æ–‡ä»¶

        Args:
            videos: è§†é¢‘åˆ—è¡¨
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            encoding: æ–‡ä»¶ç¼–ç  (é»˜è®¤ utf-8-sig ä»¥æ”¯æŒ Excel)

        Returns:
            è¾“å‡ºæ–‡ä»¶çš„ç»å¯¹è·¯å¾„
        """
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_dir = os.path.dirname(output_path)
        if output_dir:
            os.makedirs(output_dir, exist_ok=True)

        # å†™å…¥ CSV æ–‡ä»¶
        with open(output_path, "w", newline="", encoding=encoding) as f:
            writer = csv.writer(f)

            # å†™å…¥è¡¨å¤´
            writer.writerow(["å‘å¸ƒæ—¶é—´", "æ ‡é¢˜", "ä½œè€…", "è§†é¢‘é“¾æ¥"])

            # å†™å…¥æ•°æ®
            for video in videos:
                writer.writerow(
                    [video.upload_date, video.title, video.author, video.url]
                )

        abs_path = os.path.abspath(output_path)
        print(f"ğŸ’¾ å·²å¯¼å‡ºåˆ°: {abs_path}")

        return abs_path

    def run(
        self,
        channel_url: str,
        output: Optional[str] = None,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        days: Optional[int] = None,
        max_videos: Optional[int] = None,
    ) -> tuple[List[VideoEntry], Optional[str]]:
        """
        è¿è¡Œè§†é¢‘åˆ—è¡¨è·å–æµç¨‹

        Args:
            channel_url: é¢‘é“/ä½œè€… URL
            output: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            days: æœ€è¿‘ N å¤©
            max_videos: æœ€å¤§è§†é¢‘æ•°é‡

        Returns:
            (è§†é¢‘åˆ—è¡¨, CSVæ–‡ä»¶è·¯å¾„) å…ƒç»„
        """
        # è·å–è§†é¢‘åˆ—è¡¨
        videos = self.get_video_list(
            channel_url=channel_url,
            start_date=start_date,
            end_date=end_date,
            days=days,
            max_videos=max_videos,
        )

        if not videos:
            print("âš ï¸ æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„è§†é¢‘")
            return videos, None

        # ç”Ÿæˆé»˜è®¤è¾“å‡ºè·¯å¾„
        if not output:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output = f"./output/video_list_{timestamp}.csv"

        # å¯¼å‡ºåˆ° CSV
        csv_path = self.export_to_csv(videos, output)

        return videos, csv_path


def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    parser = argparse.ArgumentParser(
        description="Video List Getter - è·å–ä½œè€…/é¢‘é“çš„è§†é¢‘åˆ—è¡¨",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # è·å– YouTube é¢‘é“çš„æ‰€æœ‰è§†é¢‘
  python vlg.py https://www.youtube.com/@channel_name

  # è·å–æœ€è¿‘30å¤©çš„è§†é¢‘
  python vlg.py https://www.youtube.com/@channel_name --days 30

  # è·å–æŒ‡å®šæ—¥æœŸèŒƒå›´çš„è§†é¢‘
  python vlg.py https://www.youtube.com/@channel_name --start 2024-01-01 --end 2024-06-30

  # è·å– Bilibili ç”¨æˆ·çš„è§†é¢‘
  python vlg.py https://space.bilibili.com/12345678

  # æŒ‡å®šè¾“å‡ºæ–‡ä»¶
  python vlg.py https://www.youtube.com/@channel_name -o my_videos.csv
        """,
    )

    parser.add_argument("url", help="é¢‘é“/ä½œè€… URL (æ”¯æŒ YouTube å’Œ Bilibili)")

    parser.add_argument(
        "-o",
        "--output",
        help="è¾“å‡º CSV æ–‡ä»¶è·¯å¾„ (é»˜è®¤: ./output/video_list_æ—¶é—´æˆ³.csv)",
    )

    parser.add_argument("--start", help="å¼€å§‹æ—¥æœŸ (YYYY-MM-DD æ ¼å¼)")

    parser.add_argument("--end", help="ç»“æŸæ—¥æœŸ (YYYY-MM-DD æ ¼å¼)")

    parser.add_argument(
        "--days", type=int, help="è·å–æœ€è¿‘ N å¤©çš„è§†é¢‘ (ä¸ --start/--end äº’æ–¥)"
    )

    parser.add_argument("--max", type=int, help="æœ€å¤§è§†é¢‘æ•°é‡")

    parser.add_argument("--cookies", help="Cookies æ–‡ä»¶è·¯å¾„ (Netscape æ ¼å¼)")

    parser.add_argument("-v", "--verbose", action="store_true", help="æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—")

    args = parser.parse_args()

    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)

    # éªŒè¯å‚æ•°
    if args.days and (args.start or args.end):
        print("é”™è¯¯: --days ä¸èƒ½ä¸ --start/--end åŒæ—¶ä½¿ç”¨")
        sys.exit(1)

    print("=" * 60)
    print("ğŸ“¹ Video List Getter")
    print("=" * 60)

    # åˆ›å»ºè·å–å™¨å¹¶è¿è¡Œ
    getter = VideoListGetter(cookies_file=args.cookies)

    try:
        videos, csv_path = getter.run(
            channel_url=args.url,
            output=args.output,
            start_date=args.start,
            end_date=args.end,
            days=args.days,
            max_videos=args.max,
        )

        if videos:
            print("\n" + "=" * 60)
            print(f"âœ… å®Œæˆ! å…±å¯¼å‡º {len(videos)} ä¸ªè§†é¢‘")
            print("=" * 60)

    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        sys.exit(1)
    finally:
        if "getter" in locals():
            getter.cleanup()


if __name__ == "__main__":
    main()
